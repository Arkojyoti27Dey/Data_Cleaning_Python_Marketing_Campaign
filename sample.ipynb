{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72809752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ArrowDtype',\n",
       " 'BooleanDtype',\n",
       " 'Categorical',\n",
       " 'CategoricalDtype',\n",
       " 'CategoricalIndex',\n",
       " 'DataFrame',\n",
       " 'DateOffset',\n",
       " 'DatetimeIndex',\n",
       " 'DatetimeTZDtype',\n",
       " 'ExcelFile',\n",
       " 'ExcelWriter',\n",
       " 'Flags',\n",
       " 'Float32Dtype',\n",
       " 'Float64Dtype',\n",
       " 'Grouper',\n",
       " 'HDFStore',\n",
       " 'Index',\n",
       " 'IndexSlice',\n",
       " 'Int16Dtype',\n",
       " 'Int32Dtype',\n",
       " 'Int64Dtype',\n",
       " 'Int8Dtype',\n",
       " 'Interval',\n",
       " 'IntervalDtype',\n",
       " 'IntervalIndex',\n",
       " 'MultiIndex',\n",
       " 'NA',\n",
       " 'NaT',\n",
       " 'NamedAgg',\n",
       " 'Period',\n",
       " 'PeriodDtype',\n",
       " 'PeriodIndex',\n",
       " 'RangeIndex',\n",
       " 'Series',\n",
       " 'SparseDtype',\n",
       " 'StringDtype',\n",
       " 'Timedelta',\n",
       " 'TimedeltaIndex',\n",
       " 'Timestamp',\n",
       " 'UInt16Dtype',\n",
       " 'UInt32Dtype',\n",
       " 'UInt64Dtype',\n",
       " 'UInt8Dtype',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__docformat__',\n",
       " '__file__',\n",
       " '__git_version__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_built_with_meson',\n",
       " '_config',\n",
       " '_is_numpy_dev',\n",
       " '_libs',\n",
       " '_pandas_datetime_CAPI',\n",
       " '_pandas_parser_CAPI',\n",
       " '_testing',\n",
       " '_typing',\n",
       " '_version_meson',\n",
       " 'annotations',\n",
       " 'api',\n",
       " 'array',\n",
       " 'arrays',\n",
       " 'bdate_range',\n",
       " 'compat',\n",
       " 'concat',\n",
       " 'core',\n",
       " 'crosstab',\n",
       " 'cut',\n",
       " 'date_range',\n",
       " 'describe_option',\n",
       " 'errors',\n",
       " 'eval',\n",
       " 'factorize',\n",
       " 'from_dummies',\n",
       " 'get_dummies',\n",
       " 'get_option',\n",
       " 'infer_freq',\n",
       " 'interval_range',\n",
       " 'io',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'json_normalize',\n",
       " 'lreshape',\n",
       " 'melt',\n",
       " 'merge',\n",
       " 'merge_asof',\n",
       " 'merge_ordered',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'offsets',\n",
       " 'option_context',\n",
       " 'options',\n",
       " 'pandas',\n",
       " 'period_range',\n",
       " 'pivot',\n",
       " 'pivot_table',\n",
       " 'plotting',\n",
       " 'qcut',\n",
       " 'read_clipboard',\n",
       " 'read_csv',\n",
       " 'read_excel',\n",
       " 'read_feather',\n",
       " 'read_fwf',\n",
       " 'read_gbq',\n",
       " 'read_hdf',\n",
       " 'read_html',\n",
       " 'read_json',\n",
       " 'read_orc',\n",
       " 'read_parquet',\n",
       " 'read_pickle',\n",
       " 'read_sas',\n",
       " 'read_spss',\n",
       " 'read_sql',\n",
       " 'read_sql_query',\n",
       " 'read_sql_table',\n",
       " 'read_stata',\n",
       " 'read_table',\n",
       " 'read_xml',\n",
       " 'reset_option',\n",
       " 'set_eng_float_format',\n",
       " 'set_option',\n",
       " 'show_versions',\n",
       " 'test',\n",
       " 'testing',\n",
       " 'timedelta_range',\n",
       " 'to_datetime',\n",
       " 'to_numeric',\n",
       " 'to_pickle',\n",
       " 'to_timedelta',\n",
       " 'tseries',\n",
       " 'unique',\n",
       " 'util',\n",
       " 'value_counts',\n",
       " 'wide_to_long']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dir(pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ab026b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on CallableDynamicDoc in module pandas._config.config:\n",
      "\n",
      "<pandas._config.config.CallableDynamicDoc object>\n",
      "    set_option(pat, value)\n",
      "\n",
      "    Sets the value of the specified option.\n",
      "\n",
      "    Available options:\n",
      "\n",
      "    - compute.[use_bottleneck, use_numba, use_numexpr]\n",
      "    - display.[chop_threshold, colheader_justify, date_dayfirst, date_yearfirst,\n",
      "      encoding, expand_frame_repr, float_format]\n",
      "    - display.html.[border, table_schema, use_mathjax]\n",
      "    - display.[large_repr, max_categories, max_columns, max_colwidth, max_dir_items,\n",
      "      max_info_columns, max_info_rows, max_rows, max_seq_items, memory_usage,\n",
      "      min_rows, multi_sparse, notebook_repr_html, pprint_nest_depth, precision,\n",
      "      show_dimensions]\n",
      "    - display.unicode.[ambiguous_as_wide, east_asian_width]\n",
      "    - display.[width]\n",
      "    - future.[infer_string, no_silent_downcasting]\n",
      "    - io.excel.ods.[reader, writer]\n",
      "    - io.excel.xls.[reader]\n",
      "    - io.excel.xlsb.[reader]\n",
      "    - io.excel.xlsm.[reader, writer]\n",
      "    - io.excel.xlsx.[reader, writer]\n",
      "    - io.hdf.[default_format, dropna_table]\n",
      "    - io.parquet.[engine]\n",
      "    - io.sql.[engine]\n",
      "    - mode.[chained_assignment, copy_on_write, data_manager, sim_interactive,\n",
      "      string_storage, use_inf_as_na]\n",
      "    - plotting.[backend]\n",
      "    - plotting.matplotlib.[register_converters]\n",
      "    - styler.format.[decimal, escape, formatter, na_rep, precision, thousands]\n",
      "    - styler.html.[mathjax]\n",
      "    - styler.latex.[environment, hrules, multicol_align, multirow_align]\n",
      "    - styler.render.[encoding, max_columns, max_elements, max_rows, repr]\n",
      "    - styler.sparse.[columns, index]\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    pat : str\n",
      "        Regexp which should match a single option.\n",
      "        Note: partial matches are supported for convenience, but unless you use the\n",
      "        full option name (e.g. x.y.z.option_name), your code may break in future\n",
      "        versions if new options with similar names are introduced.\n",
      "    value : object\n",
      "        New value of option.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    None\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    OptionError if no such option exists\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Please reference the :ref:`User Guide <options>` for more information.\n",
      "\n",
      "    The available options with its descriptions:\n",
      "\n",
      "    compute.use_bottleneck : bool\n",
      "        Use the bottleneck library to accelerate if it is installed,\n",
      "        the default is True\n",
      "        Valid values: False,True\n",
      "        [default: True] [currently: True]\n",
      "    compute.use_numba : bool\n",
      "        Use the numba engine option for select operations if it is installed,\n",
      "        the default is False\n",
      "        Valid values: False,True\n",
      "        [default: False] [currently: False]\n",
      "    compute.use_numexpr : bool\n",
      "        Use the numexpr library to accelerate computation if it is installed,\n",
      "        the default is True\n",
      "        Valid values: False,True\n",
      "        [default: True] [currently: True]\n",
      "    display.chop_threshold : float or None\n",
      "        if set to a float value, all float values smaller than the given threshold\n",
      "        will be displayed as exactly 0 by repr and friends.\n",
      "        [default: None] [currently: None]\n",
      "    display.colheader_justify : 'left'/'right'\n",
      "        Controls the justification of column headers. used by DataFrameFormatter.\n",
      "        [default: right] [currently: right]\n",
      "    display.date_dayfirst : boolean\n",
      "        When True, prints and parses dates with the day first, eg 20/01/2005\n",
      "        [default: False] [currently: False]\n",
      "    display.date_yearfirst : boolean\n",
      "        When True, prints and parses dates with the year first, eg 2005/01/20\n",
      "        [default: False] [currently: False]\n",
      "    display.encoding : str/unicode\n",
      "        Defaults to the detected encoding of the console.\n",
      "        Specifies the encoding to be used for strings returned by to_string,\n",
      "        these are generally strings meant to be displayed on the console.\n",
      "        [default: UTF-8] [currently: UTF-8]\n",
      "    display.expand_frame_repr : boolean\n",
      "        Whether to print out the full DataFrame repr for wide DataFrames across\n",
      "        multiple lines, `max_columns` is still respected, but the output will\n",
      "        wrap-around across multiple \"pages\" if its width exceeds `display.width`.\n",
      "        [default: True] [currently: True]\n",
      "    display.float_format : callable\n",
      "        The callable should accept a floating point number and return\n",
      "        a string with the desired format of the number. This is used\n",
      "        in some places like SeriesFormatter.\n",
      "        See formats.format.EngFormatter for an example.\n",
      "        [default: None] [currently: None]\n",
      "    display.html.border : int\n",
      "        A ``border=value`` attribute is inserted in the ``<table>`` tag\n",
      "        for the DataFrame HTML repr.\n",
      "        [default: 1] [currently: 1]\n",
      "    display.html.table_schema : boolean\n",
      "        Whether to publish a Table Schema representation for frontends\n",
      "        that support it.\n",
      "        (default: False)\n",
      "        [default: False] [currently: False]\n",
      "    display.html.use_mathjax : boolean\n",
      "        When True, Jupyter notebook will process table contents using MathJax,\n",
      "        rendering mathematical expressions enclosed by the dollar symbol.\n",
      "        (default: True)\n",
      "        [default: True] [currently: True]\n",
      "    display.large_repr : 'truncate'/'info'\n",
      "        For DataFrames exceeding max_rows/max_cols, the repr (and HTML repr) can\n",
      "        show a truncated table, or switch to the view from\n",
      "        df.info() (the behaviour in earlier versions of pandas).\n",
      "        [default: truncate] [currently: truncate]\n",
      "    display.max_categories : int\n",
      "        This sets the maximum number of categories pandas should output when\n",
      "        printing out a `Categorical` or a Series of dtype \"category\".\n",
      "        [default: 8] [currently: 8]\n",
      "    display.max_columns : int\n",
      "        If max_cols is exceeded, switch to truncate view. Depending on\n",
      "        `large_repr`, objects are either centrally truncated or printed as\n",
      "        a summary view. 'None' value means unlimited.\n",
      "\n",
      "        In case python/IPython is running in a terminal and `large_repr`\n",
      "        equals 'truncate' this can be set to 0 or None and pandas will auto-detect\n",
      "        the width of the terminal and print a truncated object which fits\n",
      "        the screen width. The IPython notebook, IPython qtconsole, or IDLE\n",
      "        do not run in a terminal and hence it is not possible to do\n",
      "        correct auto-detection and defaults to 20.\n",
      "        [default: 20] [currently: 20]\n",
      "    display.max_colwidth : int or None\n",
      "        The maximum width in characters of a column in the repr of\n",
      "        a pandas data structure. When the column overflows, a \"...\"\n",
      "        placeholder is embedded in the output. A 'None' value means unlimited.\n",
      "        [default: 50] [currently: 50]\n",
      "    display.max_dir_items : int\n",
      "        The number of items that will be added to `dir(...)`. 'None' value means\n",
      "        unlimited. Because dir is cached, changing this option will not immediately\n",
      "        affect already existing dataframes until a column is deleted or added.\n",
      "\n",
      "        This is for instance used to suggest columns from a dataframe to tab\n",
      "        completion.\n",
      "        [default: 100] [currently: 100]\n",
      "    display.max_info_columns : int\n",
      "        max_info_columns is used in DataFrame.info method to decide if\n",
      "        per column information will be printed.\n",
      "        [default: 100] [currently: 100]\n",
      "    display.max_info_rows : int\n",
      "        df.info() will usually show null-counts for each column.\n",
      "        For large frames this can be quite slow. max_info_rows and max_info_cols\n",
      "        limit this null check only to frames with smaller dimensions than\n",
      "        specified.\n",
      "        [default: 1690785] [currently: 1690785]\n",
      "    display.max_rows : int\n",
      "        If max_rows is exceeded, switch to truncate view. Depending on\n",
      "        `large_repr`, objects are either centrally truncated or printed as\n",
      "        a summary view. 'None' value means unlimited.\n",
      "\n",
      "        In case python/IPython is running in a terminal and `large_repr`\n",
      "        equals 'truncate' this can be set to 0 and pandas will auto-detect\n",
      "        the height of the terminal and print a truncated object which fits\n",
      "        the screen height. The IPython notebook, IPython qtconsole, or\n",
      "        IDLE do not run in a terminal and hence it is not possible to do\n",
      "        correct auto-detection.\n",
      "        [default: 60] [currently: 60]\n",
      "    display.max_seq_items : int or None\n",
      "        When pretty-printing a long sequence, no more then `max_seq_items`\n",
      "        will be printed. If items are omitted, they will be denoted by the\n",
      "        addition of \"...\" to the resulting string.\n",
      "\n",
      "        If set to None, the number of items to be printed is unlimited.\n",
      "        [default: 100] [currently: 100]\n",
      "    display.memory_usage : bool, string or None\n",
      "        This specifies if the memory usage of a DataFrame should be displayed when\n",
      "        df.info() is called. Valid values True,False,'deep'\n",
      "        [default: True] [currently: True]\n",
      "    display.min_rows : int\n",
      "        The numbers of rows to show in a truncated view (when `max_rows` is\n",
      "        exceeded). Ignored when `max_rows` is set to None or 0. When set to\n",
      "        None, follows the value of `max_rows`.\n",
      "        [default: 10] [currently: 10]\n",
      "    display.multi_sparse : boolean\n",
      "        \"sparsify\" MultiIndex display (don't display repeated\n",
      "        elements in outer levels within groups)\n",
      "        [default: True] [currently: True]\n",
      "    display.notebook_repr_html : boolean\n",
      "        When True, IPython notebook will use html representation for\n",
      "        pandas objects (if it is available).\n",
      "        [default: True] [currently: True]\n",
      "    display.pprint_nest_depth : int\n",
      "        Controls the number of nested levels to process when pretty-printing\n",
      "        [default: 3] [currently: 3]\n",
      "    display.precision : int\n",
      "        Floating point output precision in terms of number of places after the\n",
      "        decimal, for regular formatting as well as scientific notation. Similar\n",
      "        to ``precision`` in :meth:`numpy.set_printoptions`.\n",
      "        [default: 6] [currently: 6]\n",
      "    display.show_dimensions : boolean or 'truncate'\n",
      "        Whether to print out dimensions at the end of DataFrame repr.\n",
      "        If 'truncate' is specified, only print out the dimensions if the\n",
      "        frame is truncated (e.g. not display all rows and/or columns)\n",
      "        [default: truncate] [currently: truncate]\n",
      "    display.unicode.ambiguous_as_wide : boolean\n",
      "        Whether to use the Unicode East Asian Width to calculate the display text\n",
      "        width.\n",
      "        Enabling this may affect to the performance (default: False)\n",
      "        [default: False] [currently: False]\n",
      "    display.unicode.east_asian_width : boolean\n",
      "        Whether to use the Unicode East Asian Width to calculate the display text\n",
      "        width.\n",
      "        Enabling this may affect to the performance (default: False)\n",
      "        [default: False] [currently: False]\n",
      "    display.width : int\n",
      "        Width of the display in characters. In case python/IPython is running in\n",
      "        a terminal this can be set to None and pandas will correctly auto-detect\n",
      "        the width.\n",
      "        Note that the IPython notebook, IPython qtconsole, or IDLE do not run in a\n",
      "        terminal and hence it is not possible to correctly detect the width.\n",
      "        [default: 80] [currently: 80]\n",
      "    future.infer_string Whether to infer sequence of str objects as pyarrow string dtype, which will be the default in pandas 3.0 (at which point this option will be deprecated).\n",
      "        [default: False] [currently: False]\n",
      "    future.no_silent_downcasting Whether to opt-in to the future behavior which will *not* silently downcast results from Series and DataFrame `where`, `mask`, and `clip` methods. Silent downcasting will be removed in pandas 3.0 (at which point this option will be deprecated).\n",
      "        [default: False] [currently: False]\n",
      "    io.excel.ods.reader : string\n",
      "        The default Excel reader engine for 'ods' files. Available options:\n",
      "        auto, odf, calamine.\n",
      "        [default: auto] [currently: auto]\n",
      "    io.excel.ods.writer : string\n",
      "        The default Excel writer engine for 'ods' files. Available options:\n",
      "        auto, odf.\n",
      "        [default: auto] [currently: auto]\n",
      "    io.excel.xls.reader : string\n",
      "        The default Excel reader engine for 'xls' files. Available options:\n",
      "        auto, xlrd, calamine.\n",
      "        [default: auto] [currently: auto]\n",
      "    io.excel.xlsb.reader : string\n",
      "        The default Excel reader engine for 'xlsb' files. Available options:\n",
      "        auto, pyxlsb, calamine.\n",
      "        [default: auto] [currently: auto]\n",
      "    io.excel.xlsm.reader : string\n",
      "        The default Excel reader engine for 'xlsm' files. Available options:\n",
      "        auto, xlrd, openpyxl, calamine.\n",
      "        [default: auto] [currently: auto]\n",
      "    io.excel.xlsm.writer : string\n",
      "        The default Excel writer engine for 'xlsm' files. Available options:\n",
      "        auto, openpyxl.\n",
      "        [default: auto] [currently: auto]\n",
      "    io.excel.xlsx.reader : string\n",
      "        The default Excel reader engine for 'xlsx' files. Available options:\n",
      "        auto, xlrd, openpyxl, calamine.\n",
      "        [default: auto] [currently: auto]\n",
      "    io.excel.xlsx.writer : string\n",
      "        The default Excel writer engine for 'xlsx' files. Available options:\n",
      "        auto, openpyxl, xlsxwriter.\n",
      "        [default: auto] [currently: auto]\n",
      "    io.hdf.default_format : format\n",
      "        default format writing format, if None, then\n",
      "        put will default to 'fixed' and append will default to 'table'\n",
      "        [default: None] [currently: None]\n",
      "    io.hdf.dropna_table : boolean\n",
      "        drop ALL nan rows when appending to a table\n",
      "        [default: False] [currently: False]\n",
      "    io.parquet.engine : string\n",
      "        The default parquet reader/writer engine. Available options:\n",
      "        'auto', 'pyarrow', 'fastparquet', the default is 'auto'\n",
      "        [default: auto] [currently: auto]\n",
      "    io.sql.engine : string\n",
      "        The default sql reader/writer engine. Available options:\n",
      "        'auto', 'sqlalchemy', the default is 'auto'\n",
      "        [default: auto] [currently: auto]\n",
      "    mode.chained_assignment : string\n",
      "        Raise an exception, warn, or no action if trying to use chained assignment,\n",
      "        The default is warn\n",
      "        [default: warn] [currently: warn]\n",
      "    mode.copy_on_write : bool\n",
      "        Use new copy-view behaviour using Copy-on-Write. Defaults to False,\n",
      "        unless overridden by the 'PANDAS_COPY_ON_WRITE' environment variable\n",
      "        (if set to \"1\" for True, needs to be set before pandas is imported).\n",
      "        [default: False] [currently: False]\n",
      "    mode.data_manager : string\n",
      "        Internal data manager type; can be \"block\" or \"array\". Defaults to \"block\",\n",
      "        unless overridden by the 'PANDAS_DATA_MANAGER' environment variable (needs\n",
      "        to be set before pandas is imported).\n",
      "        [default: block] [currently: block]\n",
      "        (Deprecated, use `` instead.)\n",
      "    mode.sim_interactive : boolean\n",
      "        Whether to simulate interactive mode for purposes of testing\n",
      "        [default: False] [currently: False]\n",
      "    mode.string_storage : string\n",
      "        The default storage for StringDtype.\n",
      "        [default: auto] [currently: auto]\n",
      "    mode.use_inf_as_na : boolean\n",
      "        True means treat None, NaN, INF, -INF as NA (old way),\n",
      "        False means None and NaN are null, but INF, -INF are not NA\n",
      "        (new way).\n",
      "\n",
      "        This option is deprecated in pandas 2.1.0 and will be removed in 3.0.\n",
      "        [default: False] [currently: False]\n",
      "        (Deprecated, use `` instead.)\n",
      "    plotting.backend : str\n",
      "        The plotting backend to use. The default value is \"matplotlib\", the\n",
      "        backend provided with pandas. Other backends can be specified by\n",
      "        providing the name of the module that implements the backend.\n",
      "        [default: matplotlib] [currently: matplotlib]\n",
      "    plotting.matplotlib.register_converters : bool or 'auto'.\n",
      "        Whether to register converters with matplotlib's units registry for\n",
      "        dates, times, datetimes, and Periods. Toggling to False will remove\n",
      "        the converters, restoring any converters that pandas overwrote.\n",
      "        [default: auto] [currently: auto]\n",
      "    styler.format.decimal : str\n",
      "        The character representation for the decimal separator for floats and complex.\n",
      "        [default: .] [currently: .]\n",
      "    styler.format.escape : str, optional\n",
      "        Whether to escape certain characters according to the given context; html or latex.\n",
      "        [default: None] [currently: None]\n",
      "    styler.format.formatter : str, callable, dict, optional\n",
      "        A formatter object to be used as default within ``Styler.format``.\n",
      "        [default: None] [currently: None]\n",
      "    styler.format.na_rep : str, optional\n",
      "        The string representation for values identified as missing.\n",
      "        [default: None] [currently: None]\n",
      "    styler.format.precision : int\n",
      "        The precision for floats and complex numbers.\n",
      "        [default: 6] [currently: 6]\n",
      "    styler.format.thousands : str, optional\n",
      "        The character representation for thousands separator for floats, int and complex.\n",
      "        [default: None] [currently: None]\n",
      "    styler.html.mathjax : bool\n",
      "        If False will render special CSS classes to table attributes that indicate Mathjax\n",
      "        will not be used in Jupyter Notebook.\n",
      "        [default: True] [currently: True]\n",
      "    styler.latex.environment : str\n",
      "        The environment to replace ``\\begin{table}``. If \"longtable\" is used results\n",
      "        in a specific longtable environment format.\n",
      "        [default: None] [currently: None]\n",
      "    styler.latex.hrules : bool\n",
      "        Whether to add horizontal rules on top and bottom and below the headers.\n",
      "        [default: False] [currently: False]\n",
      "    styler.latex.multicol_align : {\"r\", \"c\", \"l\", \"naive-l\", \"naive-r\"}\n",
      "        The specifier for horizontal alignment of sparsified LaTeX multicolumns. Pipe\n",
      "        decorators can also be added to non-naive values to draw vertical\n",
      "        rules, e.g. \"\\|r\" will draw a rule on the left side of right aligned merged cells.\n",
      "        [default: r] [currently: r]\n",
      "    styler.latex.multirow_align : {\"c\", \"t\", \"b\"}\n",
      "        The specifier for vertical alignment of sparsified LaTeX multirows.\n",
      "        [default: c] [currently: c]\n",
      "    styler.render.encoding : str\n",
      "        The encoding used for output HTML and LaTeX files.\n",
      "        [default: utf-8] [currently: utf-8]\n",
      "    styler.render.max_columns : int, optional\n",
      "        The maximum number of columns that will be rendered. May still be reduced to\n",
      "        satisfy ``max_elements``, which takes precedence.\n",
      "        [default: None] [currently: None]\n",
      "    styler.render.max_elements : int\n",
      "        The maximum number of data-cell (<td>) elements that will be rendered before\n",
      "        trimming will occur over columns, rows or both if needed.\n",
      "        [default: 262144] [currently: 262144]\n",
      "    styler.render.max_rows : int, optional\n",
      "        The maximum number of rows that will be rendered. May still be reduced to\n",
      "        satisfy ``max_elements``, which takes precedence.\n",
      "        [default: None] [currently: None]\n",
      "    styler.render.repr : str\n",
      "        Determine which output to use in Jupyter Notebook in {\"html\", \"latex\"}.\n",
      "        [default: html] [currently: html]\n",
      "    styler.sparse.columns : bool\n",
      "        Whether to sparsify the display of hierarchical columns. Setting to False will\n",
      "        display each explicit level element in a hierarchical key for each column.\n",
      "        [default: True] [currently: True]\n",
      "    styler.sparse.index : bool\n",
      "        Whether to sparsify the display of a hierarchical index. Setting to False will\n",
      "        display each explicit level element in a hierarchical key for each row.\n",
      "        [default: True] [currently: True]\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> pd.set_option('display.max_columns', 4)\n",
      "    >>> df = pd.DataFrame([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "    >>> df\n",
      "       0  1  ...  3   4\n",
      "    0  1  2  ...  4   5\n",
      "    1  6  7  ...  9  10\n",
      "    [2 rows x 5 columns]\n",
      "    >>> pd.reset_option('display.max_columns')\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(pd.set_option))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d96a60b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_csv in module pandas.io.parsers.readers:\n",
      "\n",
      "read_csv(\n",
      "    filepath_or_buffer: 'FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]',\n",
      "    *,\n",
      "    sep: 'str | None | lib.NoDefault' = <no_default>,\n",
      "    delimiter: 'str | None | lib.NoDefault' = None,\n",
      "    header: \"int | Sequence[int] | None | Literal['infer']\" = 'infer',\n",
      "    names: 'Sequence[Hashable] | None | lib.NoDefault' = <no_default>,\n",
      "    index_col: 'IndexLabel | Literal[False] | None' = None,\n",
      "    usecols: 'UsecolsArgType' = None,\n",
      "    dtype: 'DtypeArg | None' = None,\n",
      "    engine: 'CSVEngine | None' = None,\n",
      "    converters: 'Mapping[Hashable, Callable] | None' = None,\n",
      "    true_values: 'list | None' = None,\n",
      "    false_values: 'list | None' = None,\n",
      "    skipinitialspace: 'bool' = False,\n",
      "    skiprows: 'list[int] | int | Callable[[Hashable], bool] | None' = None,\n",
      "    skipfooter: 'int' = 0,\n",
      "    nrows: 'int | None' = None,\n",
      "    na_values: 'Hashable | Iterable[Hashable] | Mapping[Hashable, Iterable[Hashable]] | None' = None,\n",
      "    keep_default_na: 'bool' = True,\n",
      "    na_filter: 'bool' = True,\n",
      "    verbose: 'bool | lib.NoDefault' = <no_default>,\n",
      "    skip_blank_lines: 'bool' = True,\n",
      "    parse_dates: 'bool | Sequence[Hashable] | None' = None,\n",
      "    infer_datetime_format: 'bool | lib.NoDefault' = <no_default>,\n",
      "    keep_date_col: 'bool | lib.NoDefault' = <no_default>,\n",
      "    date_parser: 'Callable | lib.NoDefault' = <no_default>,\n",
      "    date_format: 'str | dict[Hashable, str] | None' = None,\n",
      "    dayfirst: 'bool' = False,\n",
      "    cache_dates: 'bool' = True,\n",
      "    iterator: 'bool' = False,\n",
      "    chunksize: 'int | None' = None,\n",
      "    compression: 'CompressionOptions' = 'infer',\n",
      "    thousands: 'str | None' = None,\n",
      "    decimal: 'str' = '.',\n",
      "    lineterminator: 'str | None' = None,\n",
      "    quotechar: 'str' = '\"',\n",
      "    quoting: 'int' = 0,\n",
      "    doublequote: 'bool' = True,\n",
      "    escapechar: 'str | None' = None,\n",
      "    comment: 'str | None' = None,\n",
      "    encoding: 'str | None' = None,\n",
      "    encoding_errors: 'str | None' = 'strict',\n",
      "    dialect: 'str | csv.Dialect | None' = None,\n",
      "    on_bad_lines: 'str' = 'error',\n",
      "    delim_whitespace: 'bool | lib.NoDefault' = <no_default>,\n",
      "    low_memory: 'bool' = True,\n",
      "    memory_map: 'bool' = False,\n",
      "    float_precision: \"Literal['high', 'legacy'] | None\" = None,\n",
      "    storage_options: 'StorageOptions | None' = None,\n",
      "    dtype_backend: 'DtypeBackend | lib.NoDefault' = <no_default>\n",
      ") -> 'DataFrame | TextFileReader'\n",
      "    Read a comma-separated values (csv) file into DataFrame.\n",
      "\n",
      "    Also supports optionally iterating or breaking of the file\n",
      "    into chunks.\n",
      "\n",
      "    Additional help can be found in the online docs for\n",
      "    `IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : str, path object or file-like object\n",
      "        Any valid string path is acceptable. The string could be a URL. Valid\n",
      "        URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
      "        expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "\n",
      "        If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "\n",
      "        By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "        a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "    sep : str, default ','\n",
      "        Character or regex pattern to treat as the delimiter. If ``sep=None``, the\n",
      "        C engine cannot automatically detect\n",
      "        the separator, but the Python parsing engine can, meaning the latter will\n",
      "        be used and automatically detect the separator from only the first valid\n",
      "        row of the file by Python's builtin sniffer tool, ``csv.Sniffer``.\n",
      "        In addition, separators longer than 1 character and different from\n",
      "        ``'\\s+'`` will be interpreted as regular expressions and will also force\n",
      "        the use of the Python parsing engine. Note that regex delimiters are prone\n",
      "        to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "    delimiter : str, optional\n",
      "        Alias for ``sep``.\n",
      "    header : int, Sequence of int, 'infer' or None, default 'infer'\n",
      "        Row number(s) containing column labels and marking the start of the\n",
      "        data (zero-indexed). Default behavior is to infer the column names: if no ``names``\n",
      "        are passed the behavior is identical to ``header=0`` and column\n",
      "        names are inferred from the first line of the file, if column\n",
      "        names are passed explicitly to ``names`` then the behavior is identical to\n",
      "        ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "        replace existing names. The header can be a list of integers that\n",
      "        specify row locations for a :class:`~pandas.MultiIndex` on the columns\n",
      "        e.g. ``[0, 1, 3]``. Intervening rows that are not specified will be\n",
      "        skipped (e.g. 2 in this example is skipped). Note that this\n",
      "        parameter ignores commented lines and empty lines if\n",
      "        ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "        data rather than the first line of the file.\n",
      "    names : Sequence of Hashable, optional\n",
      "        Sequence of column labels to apply. If the file contains a header row,\n",
      "        then you should explicitly pass ``header=0`` to override the column names.\n",
      "        Duplicates in this list are not allowed.\n",
      "    index_col : Hashable, Sequence of Hashable or False, optional\n",
      "      Column(s) to use as row label(s), denoted either by column labels or column\n",
      "      indices.  If a sequence of labels or indices is given, :class:`~pandas.MultiIndex`\n",
      "      will be formed for the row labels.\n",
      "\n",
      "      Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
      "      column as the index, e.g., when you have a malformed file with delimiters at\n",
      "      the end of each line.\n",
      "    usecols : Sequence of Hashable or Callable, optional\n",
      "        Subset of columns to select, denoted either by column labels or column indices.\n",
      "        If list-like, all elements must either\n",
      "        be positional (i.e. integer indices into the document columns) or strings\n",
      "        that correspond to column names provided either by the user in ``names`` or\n",
      "        inferred from the document header row(s). If ``names`` are given, the document\n",
      "        header row(s) are not taken into account. For example, a valid list-like\n",
      "        ``usecols`` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "        Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "        To instantiate a :class:`~pandas.DataFrame` from ``data`` with element order\n",
      "        preserved use ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]``\n",
      "        for columns in ``['foo', 'bar']`` order or\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "        for ``['bar', 'foo']`` order.\n",
      "\n",
      "        If callable, the callable function will be evaluated against the column\n",
      "        names, returning names where the callable function evaluates to ``True``. An\n",
      "        example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "        ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "        parsing time and lower memory usage.\n",
      "    dtype : dtype or dict of {Hashable : dtype}, optional\n",
      "        Data type(s) to apply to either the whole dataset or individual columns.\n",
      "        E.g., ``{'a': np.float64, 'b': np.int32, 'c': 'Int64'}``\n",
      "        Use ``str`` or ``object`` together with suitable ``na_values`` settings\n",
      "        to preserve and not interpret ``dtype``.\n",
      "        If ``converters`` are specified, they will be applied INSTEAD\n",
      "        of ``dtype`` conversion.\n",
      "\n",
      "        .. versionadded:: 1.5.0\n",
      "\n",
      "            Support for ``defaultdict`` was added. Specify a ``defaultdict`` as input where\n",
      "            the default determines the ``dtype`` of the columns which are not explicitly\n",
      "            listed.\n",
      "    engine : {'c', 'python', 'pyarrow'}, optional\n",
      "        Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
      "        is currently more feature-complete. Multithreading is currently only supported by\n",
      "        the pyarrow engine.\n",
      "\n",
      "        .. versionadded:: 1.4.0\n",
      "\n",
      "            The 'pyarrow' engine was added as an *experimental* engine, and some features\n",
      "            are unsupported, or may not work correctly, with this engine.\n",
      "    converters : dict of {Hashable : Callable}, optional\n",
      "        Functions for converting values in specified columns. Keys can either\n",
      "        be column labels or column indices.\n",
      "    true_values : list, optional\n",
      "        Values to consider as ``True`` in addition to case-insensitive variants of 'True'.\n",
      "    false_values : list, optional\n",
      "        Values to consider as ``False`` in addition to case-insensitive variants of 'False'.\n",
      "    skipinitialspace : bool, default False\n",
      "        Skip spaces after delimiter.\n",
      "    skiprows : int, list of int or Callable, optional\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (``int``)\n",
      "        at the start of the file.\n",
      "\n",
      "        If callable, the callable function will be evaluated against the row\n",
      "        indices, returning ``True`` if the row should be skipped and ``False`` otherwise.\n",
      "        An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "    skipfooter : int, default 0\n",
      "        Number of lines at bottom of file to skip (Unsupported with ``engine='c'``).\n",
      "    nrows : int, optional\n",
      "        Number of rows of file to read. Useful for reading pieces of large files.\n",
      "    na_values : Hashable, Iterable of Hashable or dict of {Hashable : Iterable}, optional\n",
      "        Additional strings to recognize as ``NA``/``NaN``. If ``dict`` passed, specific\n",
      "        per-column ``NA`` values.  By default the following values are interpreted as\n",
      "        ``NaN``: \" \", \"#N/A\", \"#N/A N/A\", \"#NA\", \"-1.#IND\", \"-1.#QNAN\", \"-NaN\", \"-nan\",\n",
      "        \"1.#IND\", \"1.#QNAN\", \"<NA>\", \"N/A\", \"NA\", \"NULL\", \"NaN\", \"None\",\n",
      "        \"n/a\", \"nan\", \"null \".\n",
      "\n",
      "    keep_default_na : bool, default True\n",
      "        Whether or not to include the default ``NaN`` values when parsing the data.\n",
      "        Depending on whether ``na_values`` is passed in, the behavior is as follows:\n",
      "\n",
      "        * If ``keep_default_na`` is ``True``, and ``na_values`` are specified, ``na_values``\n",
      "          is appended to the default ``NaN`` values used for parsing.\n",
      "        * If ``keep_default_na`` is ``True``, and ``na_values`` are not specified, only\n",
      "          the default ``NaN`` values are used for parsing.\n",
      "        * If ``keep_default_na`` is ``False``, and ``na_values`` are specified, only\n",
      "          the ``NaN`` values specified ``na_values`` are used for parsing.\n",
      "        * If ``keep_default_na`` is ``False``, and ``na_values`` are not specified, no\n",
      "          strings will be parsed as ``NaN``.\n",
      "\n",
      "        Note that if ``na_filter`` is passed in as ``False``, the ``keep_default_na`` and\n",
      "        ``na_values`` parameters will be ignored.\n",
      "    na_filter : bool, default True\n",
      "        Detect missing value markers (empty strings and the value of ``na_values``). In\n",
      "        data without any ``NA`` values, passing ``na_filter=False`` can improve the\n",
      "        performance of reading a large file.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of ``NA`` values placed in non-numeric columns.\n",
      "\n",
      "        .. deprecated:: 2.2.0\n",
      "    skip_blank_lines : bool, default True\n",
      "        If ``True``, skip over blank lines rather than interpreting as ``NaN`` values.\n",
      "    parse_dates : bool, list of Hashable, list of lists or dict of {Hashable : list}, default False\n",
      "        The behavior is as follows:\n",
      "\n",
      "        * ``bool``. If ``True`` -> try parsing the index. Note: Automatically set to\n",
      "          ``True`` if ``date_format`` or ``date_parser`` arguments have been passed.\n",
      "        * ``list`` of ``int`` or names. e.g. If ``[1, 2, 3]`` -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * ``list`` of ``list``. e.g.  If ``[[1, 3]]`` -> combine columns 1 and 3 and parse\n",
      "          as a single date column. Values are joined with a space before parsing.\n",
      "        * ``dict``, e.g. ``{'foo' : [1, 3]}`` -> parse columns 1, 3 as date and call\n",
      "          result 'foo'. Values are joined with a space before parsing.\n",
      "\n",
      "        If a column or index cannot be represented as an array of ``datetime``,\n",
      "        say because of an unparsable value or a mixture of timezones, the column\n",
      "        or index will be returned unaltered as an ``object`` data type. For\n",
      "        non-standard ``datetime`` parsing, use :func:`~pandas.to_datetime` after\n",
      "        :func:`~pandas.read_csv`.\n",
      "\n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    infer_datetime_format : bool, default False\n",
      "        If ``True`` and ``parse_dates`` is enabled, pandas will attempt to infer the\n",
      "        format of the ``datetime`` strings in the columns, and if it can be inferred,\n",
      "        switch to a faster method of parsing them. In some cases this can increase\n",
      "        the parsing speed by 5-10x.\n",
      "\n",
      "        .. deprecated:: 2.0.0\n",
      "            A strict version of this argument is now the default, passing it has no effect.\n",
      "\n",
      "    keep_date_col : bool, default False\n",
      "        If ``True`` and ``parse_dates`` specifies combining multiple columns then\n",
      "        keep the original columns.\n",
      "    date_parser : Callable, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        ``datetime`` instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. pandas will try to call ``date_parser`` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by ``parse_dates``) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by ``parse_dates`` into a single array\n",
      "        and pass that; and 3) call ``date_parser`` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by ``parse_dates``) as\n",
      "        arguments.\n",
      "\n",
      "        .. deprecated:: 2.0.0\n",
      "           Use ``date_format`` instead, or read in as ``object`` and then apply\n",
      "           :func:`~pandas.to_datetime` as-needed.\n",
      "    date_format : str or dict of column -> format, optional\n",
      "        Format to use for parsing dates when used in conjunction with ``parse_dates``.\n",
      "        The strftime to parse time, e.g. :const:`\"%d/%m/%Y\"`. See\n",
      "        `strftime documentation\n",
      "        <https://docs.python.org/3/library/datetime.html\n",
      "        #strftime-and-strptime-behavior>`_ for more information on choices, though\n",
      "        note that :const:`\"%f\"` will parse all the way up to nanoseconds.\n",
      "        You can also pass:\n",
      "\n",
      "        - \"ISO8601\", to parse any `ISO8601 <https://en.wikipedia.org/wiki/ISO_8601>`_\n",
      "            time string (not necessarily in exactly the same format);\n",
      "        - \"mixed\", to infer the format for each element individually. This is risky,\n",
      "            and you should probably use it along with `dayfirst`.\n",
      "\n",
      "        .. versionadded:: 2.0.0\n",
      "    dayfirst : bool, default False\n",
      "        DD/MM format dates, international and European format.\n",
      "    cache_dates : bool, default True\n",
      "        If ``True``, use a cache of unique, converted dates to apply the ``datetime``\n",
      "        conversion. May produce significant speed-up when parsing duplicate\n",
      "        date strings, especially ones with timezone offsets.\n",
      "\n",
      "    iterator : bool, default False\n",
      "        Return ``TextFileReader`` object for iteration or getting chunks with\n",
      "        ``get_chunk()``.\n",
      "    chunksize : int, optional\n",
      "        Number of lines to read from the file per chunk. Passing a value will cause the\n",
      "        function to return a ``TextFileReader`` object for iteration.\n",
      "        See the `IO Tools docs\n",
      "        <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "        for more information on ``iterator`` and ``chunksize``.\n",
      "\n",
      "    compression : str or dict, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer' and 'filepath_or_buffer' is\n",
      "        path-like, then detect compression from the following extensions: '.gz',\n",
      "        '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "        (otherwise no compression).\n",
      "        If using 'zip' or 'tar', the ZIP file must contain only one data file to be read in.\n",
      "        Set to ``None`` for no decompression.\n",
      "        Can also be a dict with key ``'method'`` set\n",
      "        to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      "        other key-value pairs are forwarded to\n",
      "        ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "        ``bz2.BZ2File``, ``zstandard.ZstdDecompressor``, ``lzma.LZMAFile`` or\n",
      "        ``tarfile.TarFile``, respectively.\n",
      "        As an example, the following could be passed for Zstandard decompression using a\n",
      "        custom compression dictionary:\n",
      "        ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
      "\n",
      "        .. versionadded:: 1.5.0\n",
      "            Added support for `.tar` files.\n",
      "\n",
      "        .. versionchanged:: 1.4.0 Zstandard support.\n",
      "\n",
      "    thousands : str (length 1), optional\n",
      "        Character acting as the thousands separator in numerical values.\n",
      "    decimal : str (length 1), default '.'\n",
      "        Character to recognize as decimal point (e.g., use ',' for European data).\n",
      "    lineterminator : str (length 1), optional\n",
      "        Character used to denote a line break. Only valid with C parser.\n",
      "    quotechar : str (length 1), optional\n",
      "        Character used to denote the start and end of a quoted item. Quoted\n",
      "        items can include the ``delimiter`` and it will be ignored.\n",
      "    quoting : {0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL, 2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}, default csv.QUOTE_MINIMAL\n",
      "        Control field quoting behavior per ``csv.QUOTE_*`` constants. Default is\n",
      "        ``csv.QUOTE_MINIMAL`` (i.e., 0) which implies that only fields containing special\n",
      "        characters are quoted (e.g., characters defined in ``quotechar``, ``delimiter``,\n",
      "        or ``lineterminator``.\n",
      "    doublequote : bool, default True\n",
      "       When ``quotechar`` is specified and ``quoting`` is not ``QUOTE_NONE``, indicate\n",
      "       whether or not to interpret two consecutive ``quotechar`` elements INSIDE a\n",
      "       field as a single ``quotechar`` element.\n",
      "    escapechar : str (length 1), optional\n",
      "        Character used to escape other characters.\n",
      "    comment : str (length 1), optional\n",
      "        Character indicating that the remainder of line should not be parsed.\n",
      "        If found at the beginning\n",
      "        of a line, the line will be ignored altogether. This parameter must be a\n",
      "        single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "        fully commented lines are ignored by the parameter ``header`` but not by\n",
      "        ``skiprows``. For example, if ``comment='#'``, parsing\n",
      "        ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in ``'a,b,c'`` being\n",
      "        treated as the header.\n",
      "    encoding : str, optional, default 'utf-8'\n",
      "        Encoding to use for UTF when reading/writing (ex. ``'utf-8'``). `List of Python\n",
      "        standard encodings\n",
      "        <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "\n",
      "    encoding_errors : str, optional, default 'strict'\n",
      "        How encoding errors are treated. `List of possible values\n",
      "        <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
      "\n",
      "        .. versionadded:: 1.3.0\n",
      "\n",
      "    dialect : str or csv.Dialect, optional\n",
      "        If provided, this parameter will override values (default or not) for the\n",
      "        following parameters: ``delimiter``, ``doublequote``, ``escapechar``,\n",
      "        ``skipinitialspace``, ``quotechar``, and ``quoting``. If it is necessary to\n",
      "        override values, a ``ParserWarning`` will be issued. See ``csv.Dialect``\n",
      "        documentation for more details.\n",
      "    on_bad_lines : {'error', 'warn', 'skip'} or Callable, default 'error'\n",
      "        Specifies what to do upon encountering a bad line (a line with too many fields).\n",
      "        Allowed values are :\n",
      "\n",
      "        - ``'error'``, raise an Exception when a bad line is encountered.\n",
      "        - ``'warn'``, raise a warning when a bad line is encountered and skip that line.\n",
      "        - ``'skip'``, skip bad lines without raising or warning when they are encountered.\n",
      "\n",
      "        .. versionadded:: 1.3.0\n",
      "\n",
      "        .. versionadded:: 1.4.0\n",
      "\n",
      "            - Callable, function with signature\n",
      "              ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
      "              bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
      "              If the function returns ``None``, the bad line will be ignored.\n",
      "              If the function returns a new ``list`` of strings with more elements than\n",
      "              expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
      "              Only supported when ``engine='python'``\n",
      "\n",
      "        .. versionchanged:: 2.2.0\n",
      "\n",
      "            - Callable, function with signature\n",
      "              as described in `pyarrow documentation\n",
      "              <https://arrow.apache.org/docs/python/generated/pyarrow.csv.ParseOptions.html\n",
      "              #pyarrow.csv.ParseOptions.invalid_row_handler>`_ when ``engine='pyarrow'``\n",
      "\n",
      "    delim_whitespace : bool, default False\n",
      "        Specifies whether or not whitespace (e.g. ``' '`` or ``'\\t'``) will be\n",
      "        used as the ``sep`` delimiter. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "        is set to ``True``, nothing should be passed in for the ``delimiter``\n",
      "        parameter.\n",
      "\n",
      "        .. deprecated:: 2.2.0\n",
      "            Use ``sep=\"\\s+\"`` instead.\n",
      "    low_memory : bool, default True\n",
      "        Internally process the file in chunks, resulting in lower memory use\n",
      "        while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "        types either set ``False``, or specify the type with the ``dtype`` parameter.\n",
      "        Note that the entire file is read into a single :class:`~pandas.DataFrame`\n",
      "        regardless, use the ``chunksize`` or ``iterator`` parameter to return the data in\n",
      "        chunks. (Only valid with C parser).\n",
      "    memory_map : bool, default False\n",
      "        If a filepath is provided for ``filepath_or_buffer``, map the file object\n",
      "        directly onto memory and access the data directly from there. Using this\n",
      "        option can improve performance because there is no longer any I/O overhead.\n",
      "    float_precision : {'high', 'legacy', 'round_trip'}, optional\n",
      "        Specifies which converter the C engine should use for floating-point\n",
      "        values. The options are ``None`` or ``'high'`` for the ordinary converter,\n",
      "        ``'legacy'`` for the original lower precision pandas converter, and\n",
      "        ``'round_trip'`` for the round-trip converter.\n",
      "\n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "\n",
      "    dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
      "        Back-end data type applied to the resultant :class:`DataFrame`\n",
      "        (still experimental). Behaviour is as follows:\n",
      "\n",
      "        * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
      "          (default).\n",
      "        * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
      "          DataFrame.\n",
      "\n",
      "        .. versionadded:: 2.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or TextFileReader\n",
      "        A comma-separated values (csv) file is returned as two-dimensional\n",
      "        data structure with labeled axes.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_table : Read general delimited file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(pd.read_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b88747fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function print in module builtins:\n",
      "\n",
      "print(*args, sep=' ', end='\\n', file=None, flush=False)\n",
      "    Prints the values to a stream, or to sys.stdout by default.\n",
      "\n",
      "    sep\n",
      "      string inserted between values, default a space.\n",
      "    end\n",
      "      string appended after the last value, default a newline.\n",
      "    file\n",
      "      a file-like object (stream); defaults to the current sys.stdout.\n",
      "    flush\n",
      "      whether to forcibly flush the stream.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aab81d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function display in module IPython.core.display_functions:\n",
      "\n",
      "display(\n",
      "    *objs,\n",
      "    include=None,\n",
      "    exclude=None,\n",
      "    metadata=None,\n",
      "    transient=None,\n",
      "    display_id=None,\n",
      "    raw=False,\n",
      "    clear=False,\n",
      "    **kwargs\n",
      ")\n",
      "    Display a Python object in all frontends.\n",
      "\n",
      "    By default all representations will be computed and sent to the frontends.\n",
      "    Frontends can decide which representation is used and how.\n",
      "\n",
      "    In terminal IPython this will be similar to using :func:`print`, for use in richer\n",
      "    frontends see Jupyter notebook examples with rich display logic.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    *objs : object\n",
      "        The Python objects to display.\n",
      "    raw : bool, optional\n",
      "        Are the objects to be displayed already mimetype-keyed dicts of raw display data,\n",
      "        or Python objects that need to be formatted before display? [default: False]\n",
      "    include : list, tuple or set, optional\n",
      "        A list of format type strings (MIME types) to include in the\n",
      "        format data dict. If this is set *only* the format types included\n",
      "        in this list will be computed.\n",
      "    exclude : list, tuple or set, optional\n",
      "        A list of format type strings (MIME types) to exclude in the format\n",
      "        data dict. If this is set all format types will be computed,\n",
      "        except for those included in this argument.\n",
      "    metadata : dict, optional\n",
      "        A dictionary of metadata to associate with the output.\n",
      "        mime-type keys in this dictionary will be associated with the individual\n",
      "        representation formats, if they exist.\n",
      "    transient : dict, optional\n",
      "        A dictionary of transient data to associate with the output.\n",
      "        Data in this dict should not be persisted to files (e.g. notebooks).\n",
      "    display_id : str, bool optional\n",
      "        Set an id for the display.\n",
      "        This id can be used for updating this display area later via update_display.\n",
      "        If given as `True`, generate a new `display_id`\n",
      "    clear : bool, optional\n",
      "        Should the output area be cleared before displaying anything? If True,\n",
      "        this will wait for additional output before clearing. [default: False]\n",
      "    **kwargs : additional keyword-args, optional\n",
      "        Additional keyword-arguments are passed through to the display publisher.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    handle: DisplayHandle\n",
      "        Returns a handle on updatable displays for use with :func:`update_display`,\n",
      "        if `display_id` is given. Returns :any:`None` if no `display_id` is given\n",
      "        (default).\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> class Json(object):\n",
      "    ...     def __init__(self, json):\n",
      "    ...         self.json = json\n",
      "    ...     def _repr_pretty_(self, pp, cycle):\n",
      "    ...         import json\n",
      "    ...         pp.text(json.dumps(self.json, indent=2))\n",
      "    ...     def __repr__(self):\n",
      "    ...         return str(self.json)\n",
      "    ...\n",
      "\n",
      "    >>> d = Json({1:2, 3: {4:5}})\n",
      "\n",
      "    >>> print(d)\n",
      "    {1: 2, 3: {4: 5}}\n",
      "\n",
      "    >>> display(d)\n",
      "    {\n",
      "      \"1\": 2,\n",
      "      \"3\": {\n",
      "        \"4\": 5\n",
      "      }\n",
      "    }\n",
      "\n",
      "    >>> def int_formatter(integer, pp, cycle):\n",
      "    ...     pp.text('I'*integer)\n",
      "\n",
      "    >>> plain = get_ipython().display_formatter.formatters['text/plain']\n",
      "    >>> plain.for_type(int, int_formatter)\n",
      "    <function _repr_pprint at 0x...>\n",
      "    >>> display(7-5)\n",
      "    II\n",
      "\n",
      "    >>> del plain.type_printers[int]\n",
      "    >>> display(7-5)\n",
      "    2\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    :func:`update_display`\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    In Python, objects can declare their textual representation using the\n",
      "    `__repr__` method. IPython expands on this idea and allows objects to declare\n",
      "    other, rich representations including:\n",
      "\n",
      "      - HTML\n",
      "      - JSON\n",
      "      - PNG\n",
      "      - JPEG\n",
      "      - SVG\n",
      "      - LaTeX\n",
      "\n",
      "    A single object can declare some or all of these representations; all are\n",
      "    handled by IPython's display system.\n",
      "\n",
      "    The main idea of the first approach is that you have to implement special\n",
      "    display methods when you define your class, one for each representation you\n",
      "    want to use. Here is a list of the names of the special methods and the\n",
      "    values they must return:\n",
      "\n",
      "      - `_repr_html_`: return raw HTML as a string, or a tuple (see below).\n",
      "      - `_repr_json_`: return a JSONable dict, or a tuple (see below).\n",
      "      - `_repr_jpeg_`: return raw JPEG data, or a tuple (see below).\n",
      "      - `_repr_png_`: return raw PNG data, or a tuple (see below).\n",
      "      - `_repr_svg_`: return raw SVG data as a string, or a tuple (see below).\n",
      "      - `_repr_latex_`: return LaTeX commands in a string surrounded by \"$\",\n",
      "                        or a tuple (see below).\n",
      "      - `_repr_mimebundle_`: return a full mimebundle containing the mapping\n",
      "                             from all mimetypes to data.\n",
      "                             Use this for any mime-type not listed above.\n",
      "\n",
      "    The above functions may also return the object's metadata alonside the\n",
      "    data.  If the metadata is available, the functions will return a tuple\n",
      "    containing the data and metadata, in that order.  If there is no metadata\n",
      "    available, then the functions will return the data only.\n",
      "\n",
      "    When you are directly writing your own classes, you can adapt them for\n",
      "    display in IPython by following the above approach. But in practice, you\n",
      "    often need to work with existing classes that you can't easily modify.\n",
      "\n",
      "    You can refer to the documentation on integrating with the display system in\n",
      "    order to register custom formatters for already existing types\n",
      "    (:ref:`integrating_rich_display`).\n",
      "\n",
      "    .. versionadded:: 5.4 display available without import\n",
      "    .. versionadded:: 6.1 display available without import\n",
      "\n",
      "    Since IPython 5.4 and 6.1 :func:`display` is automatically made available to\n",
      "    the user without import. If you are using display in a document that might\n",
      "    be used in a pure python context or with older version of IPython, use the\n",
      "    following import at the top of your file::\n",
      "\n",
      "        from IPython.display import display\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ff55941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '_AXIS_LEN',\n",
       " '_AXIS_ORDERS',\n",
       " '_AXIS_TO_AXIS_NUMBER',\n",
       " '_HANDLED_TYPES',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_ufunc__',\n",
       " '__arrow_c_stream__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__dataframe__',\n",
       " '__dataframe_consortium_standard__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__finalize__',\n",
       " '__firstlineno__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pandas_priority__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__static_attributes__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_accessors',\n",
       " '_accum_func',\n",
       " '_agg_examples_doc',\n",
       " '_agg_see_also_doc',\n",
       " '_align_for_op',\n",
       " '_align_frame',\n",
       " '_align_series',\n",
       " '_append',\n",
       " '_arith_method',\n",
       " '_arith_method_with_reindex',\n",
       " '_as_manager',\n",
       " '_box_col_values',\n",
       " '_can_fast_transpose',\n",
       " '_check_inplace_and_allows_duplicate_labels',\n",
       " '_check_is_chained_assignment_possible',\n",
       " '_check_label_or_level_ambiguity',\n",
       " '_check_setitem_copy',\n",
       " '_clear_item_cache',\n",
       " '_clip_with_one_bound',\n",
       " '_clip_with_scalar',\n",
       " '_cmp_method',\n",
       " '_combine_frame',\n",
       " '_consolidate',\n",
       " '_consolidate_inplace',\n",
       " '_construct_axes_dict',\n",
       " '_construct_result',\n",
       " '_constructor',\n",
       " '_constructor_from_mgr',\n",
       " '_constructor_sliced',\n",
       " '_constructor_sliced_from_mgr',\n",
       " '_create_data_for_split_and_tight_to_dict',\n",
       " '_data',\n",
       " '_deprecate_downcast',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_dispatch_frame_op',\n",
       " '_drop_axis',\n",
       " '_drop_labels_or_levels',\n",
       " '_ensure_valid_index',\n",
       " '_find_valid_index',\n",
       " '_flex_arith_method',\n",
       " '_flex_cmp_method',\n",
       " '_from_arrays',\n",
       " '_from_mgr',\n",
       " '_get_agg_axis',\n",
       " '_get_axis',\n",
       " '_get_axis_name',\n",
       " '_get_axis_number',\n",
       " '_get_axis_resolvers',\n",
       " '_get_block_manager_axis',\n",
       " '_get_bool_data',\n",
       " '_get_cleaned_column_resolvers',\n",
       " '_get_column_array',\n",
       " '_get_index_resolvers',\n",
       " '_get_item_cache',\n",
       " '_get_label_or_level_values',\n",
       " '_get_numeric_data',\n",
       " '_get_value',\n",
       " '_get_values_for_csv',\n",
       " '_getitem_bool_array',\n",
       " '_getitem_multilevel',\n",
       " '_getitem_nocopy',\n",
       " '_getitem_slice',\n",
       " '_gotitem',\n",
       " '_hidden_attrs',\n",
       " '_indexed_same',\n",
       " '_info_axis',\n",
       " '_info_axis_name',\n",
       " '_info_axis_number',\n",
       " '_info_repr',\n",
       " '_init_mgr',\n",
       " '_inplace_method',\n",
       " '_internal_names',\n",
       " '_internal_names_set',\n",
       " '_is_copy',\n",
       " '_is_homogeneous_type',\n",
       " '_is_label_or_level_reference',\n",
       " '_is_label_reference',\n",
       " '_is_level_reference',\n",
       " '_is_mixed_type',\n",
       " '_is_view',\n",
       " '_is_view_after_cow_rules',\n",
       " '_iset_item',\n",
       " '_iset_item_mgr',\n",
       " '_iset_not_inplace',\n",
       " '_iter_column_arrays',\n",
       " '_ixs',\n",
       " '_logical_func',\n",
       " '_logical_method',\n",
       " '_maybe_align_series_as_frame',\n",
       " '_maybe_cache_changed',\n",
       " '_maybe_update_cacher',\n",
       " '_metadata',\n",
       " '_min_count_stat_function',\n",
       " '_needs_reindex_multi',\n",
       " '_pad_or_backfill',\n",
       " '_protect_consolidate',\n",
       " '_reduce',\n",
       " '_reduce_axis1',\n",
       " '_reindex_axes',\n",
       " '_reindex_multi',\n",
       " '_reindex_with_indexers',\n",
       " '_rename',\n",
       " '_replace_columnwise',\n",
       " '_repr_data_resource_',\n",
       " '_repr_fits_horizontal_',\n",
       " '_repr_fits_vertical_',\n",
       " '_repr_html_',\n",
       " '_repr_latex_',\n",
       " '_reset_cache',\n",
       " '_reset_cacher',\n",
       " '_sanitize_column',\n",
       " '_series',\n",
       " '_set_axis',\n",
       " '_set_axis_name',\n",
       " '_set_axis_nocheck',\n",
       " '_set_is_copy',\n",
       " '_set_item',\n",
       " '_set_item_frame_value',\n",
       " '_set_item_mgr',\n",
       " '_set_value',\n",
       " '_setitem_array',\n",
       " '_setitem_frame',\n",
       " '_setitem_slice',\n",
       " '_shift_with_freq',\n",
       " '_should_reindex_frame_op',\n",
       " '_slice',\n",
       " '_stat_function',\n",
       " '_stat_function_ddof',\n",
       " '_take_with_is_copy',\n",
       " '_to_dict_of_blocks',\n",
       " '_to_latex_via_styler',\n",
       " '_typ',\n",
       " '_update_inplace',\n",
       " '_validate_dtype',\n",
       " '_values',\n",
       " '_where',\n",
       " 'abs',\n",
       " 'add',\n",
       " 'add_prefix',\n",
       " 'add_suffix',\n",
       " 'agg',\n",
       " 'aggregate',\n",
       " 'align',\n",
       " 'all',\n",
       " 'any',\n",
       " 'apply',\n",
       " 'applymap',\n",
       " 'asfreq',\n",
       " 'asof',\n",
       " 'assign',\n",
       " 'astype',\n",
       " 'at',\n",
       " 'at_time',\n",
       " 'attrs',\n",
       " 'axes',\n",
       " 'backfill',\n",
       " 'between_time',\n",
       " 'bfill',\n",
       " 'bool',\n",
       " 'boxplot',\n",
       " 'clip',\n",
       " 'columns',\n",
       " 'combine',\n",
       " 'combine_first',\n",
       " 'compare',\n",
       " 'convert_dtypes',\n",
       " 'copy',\n",
       " 'corr',\n",
       " 'corrwith',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'describe',\n",
       " 'diff',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'dot',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'droplevel',\n",
       " 'dropna',\n",
       " 'dtypes',\n",
       " 'duplicated',\n",
       " 'empty',\n",
       " 'eq',\n",
       " 'equals',\n",
       " 'eval',\n",
       " 'ewm',\n",
       " 'expanding',\n",
       " 'explode',\n",
       " 'ffill',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'first_valid_index',\n",
       " 'flags',\n",
       " 'floordiv',\n",
       " 'from_dict',\n",
       " 'from_records',\n",
       " 'ge',\n",
       " 'get',\n",
       " 'groupby',\n",
       " 'gt',\n",
       " 'head',\n",
       " 'hist',\n",
       " 'iat',\n",
       " 'idxmax',\n",
       " 'idxmin',\n",
       " 'iloc',\n",
       " 'index',\n",
       " 'infer_objects',\n",
       " 'info',\n",
       " 'insert',\n",
       " 'interpolate',\n",
       " 'isetitem',\n",
       " 'isin',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'items',\n",
       " 'iterrows',\n",
       " 'itertuples',\n",
       " 'join',\n",
       " 'keys',\n",
       " 'kurt',\n",
       " 'kurtosis',\n",
       " 'last',\n",
       " 'last_valid_index',\n",
       " 'le',\n",
       " 'loc',\n",
       " 'lt',\n",
       " 'map',\n",
       " 'mask',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'melt',\n",
       " 'memory_usage',\n",
       " 'merge',\n",
       " 'min',\n",
       " 'mod',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'multiply',\n",
       " 'ndim',\n",
       " 'ne',\n",
       " 'nlargest',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'nsmallest',\n",
       " 'nunique',\n",
       " 'pad',\n",
       " 'pct_change',\n",
       " 'pipe',\n",
       " 'pivot',\n",
       " 'pivot_table',\n",
       " 'plot',\n",
       " 'pop',\n",
       " 'pow',\n",
       " 'prod',\n",
       " 'product',\n",
       " 'quantile',\n",
       " 'query',\n",
       " 'radd',\n",
       " 'rank',\n",
       " 'rdiv',\n",
       " 'reindex',\n",
       " 'reindex_like',\n",
       " 'rename',\n",
       " 'rename_axis',\n",
       " 'reorder_levels',\n",
       " 'replace',\n",
       " 'resample',\n",
       " 'reset_index',\n",
       " 'rfloordiv',\n",
       " 'rmod',\n",
       " 'rmul',\n",
       " 'rolling',\n",
       " 'round',\n",
       " 'rpow',\n",
       " 'rsub',\n",
       " 'rtruediv',\n",
       " 'sample',\n",
       " 'select_dtypes',\n",
       " 'sem',\n",
       " 'set_axis',\n",
       " 'set_flags',\n",
       " 'set_index',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'skew',\n",
       " 'sort_index',\n",
       " 'sort_values',\n",
       " 'sparse',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'std',\n",
       " 'style',\n",
       " 'sub',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'swaplevel',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'to_clipboard',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_excel',\n",
       " 'to_feather',\n",
       " 'to_gbq',\n",
       " 'to_hdf',\n",
       " 'to_html',\n",
       " 'to_json',\n",
       " 'to_latex',\n",
       " 'to_markdown',\n",
       " 'to_numpy',\n",
       " 'to_orc',\n",
       " 'to_parquet',\n",
       " 'to_period',\n",
       " 'to_pickle',\n",
       " 'to_records',\n",
       " 'to_sql',\n",
       " 'to_stata',\n",
       " 'to_string',\n",
       " 'to_timestamp',\n",
       " 'to_xarray',\n",
       " 'to_xml',\n",
       " 'transform',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncate',\n",
       " 'tz_convert',\n",
       " 'tz_localize',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'value_counts',\n",
       " 'values',\n",
       " 'var',\n",
       " 'where',\n",
       " 'xs']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "426c3d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function to_excel in module pandas.core.generic:\n",
      "\n",
      "to_excel(\n",
      "    self,\n",
      "    excel_writer: 'FilePath | WriteExcelBuffer | ExcelWriter',\n",
      "    *,\n",
      "    sheet_name: 'str' = 'Sheet1',\n",
      "    na_rep: 'str' = '',\n",
      "    float_format: 'str | None' = None,\n",
      "    columns: 'Sequence[Hashable] | None' = None,\n",
      "    header: 'Sequence[Hashable] | bool_t' = True,\n",
      "    index: 'bool_t' = True,\n",
      "    index_label: 'IndexLabel | None' = None,\n",
      "    startrow: 'int' = 0,\n",
      "    startcol: 'int' = 0,\n",
      "    engine: \"Literal['openpyxl', 'xlsxwriter'] | None\" = None,\n",
      "    merge_cells: 'bool_t' = True,\n",
      "    inf_rep: 'str' = 'inf',\n",
      "    freeze_panes: 'tuple[int, int] | None' = None,\n",
      "    storage_options: 'StorageOptions | None' = None,\n",
      "    engine_kwargs: 'dict[str, Any] | None' = None\n",
      ") -> 'None'\n",
      "    Write object to an Excel sheet.\n",
      "\n",
      "    To write a single object to an Excel .xlsx file it is only necessary to\n",
      "    specify a target file name. To write to multiple sheets it is necessary to\n",
      "    create an `ExcelWriter` object with a target file name, and specify a sheet\n",
      "    in the file to write to.\n",
      "\n",
      "    Multiple sheets may be written to by specifying unique `sheet_name`.\n",
      "    With all data written to the file it is necessary to save the changes.\n",
      "    Note that creating an `ExcelWriter` object with a file name that already\n",
      "    exists will result in the contents of the existing file being erased.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    excel_writer : path-like, file-like, or ExcelWriter object\n",
      "        File path or existing ExcelWriter.\n",
      "    sheet_name : str, default 'Sheet1'\n",
      "        Name of sheet which will contain DataFrame.\n",
      "    na_rep : str, default ''\n",
      "        Missing data representation.\n",
      "    float_format : str, optional\n",
      "        Format string for floating point numbers. For example\n",
      "        ``float_format=\"%.2f\"`` will format 0.1234 to 0.12.\n",
      "    columns : sequence or list of str, optional\n",
      "        Columns to write.\n",
      "    header : bool or list of str, default True\n",
      "        Write out the column names. If a list of string is given it is\n",
      "        assumed to be aliases for the column names.\n",
      "    index : bool, default True\n",
      "        Write row names (index).\n",
      "    index_label : str or sequence, optional\n",
      "        Column label for index column(s) if desired. If not specified, and\n",
      "        `header` and `index` are True, then the index names are used. A\n",
      "        sequence should be given if the DataFrame uses MultiIndex.\n",
      "    startrow : int, default 0\n",
      "        Upper left cell row to dump data frame.\n",
      "    startcol : int, default 0\n",
      "        Upper left cell column to dump data frame.\n",
      "    engine : str, optional\n",
      "        Write engine to use, 'openpyxl' or 'xlsxwriter'. You can also set this\n",
      "        via the options ``io.excel.xlsx.writer`` or\n",
      "        ``io.excel.xlsm.writer``.\n",
      "\n",
      "    merge_cells : bool, default True\n",
      "        Write MultiIndex and Hierarchical Rows as merged cells.\n",
      "    inf_rep : str, default 'inf'\n",
      "        Representation for infinity (there is no native representation for\n",
      "        infinity in Excel).\n",
      "    freeze_panes : tuple of int (length 2), optional\n",
      "        Specifies the one-based bottommost row and rightmost column that\n",
      "        is to be frozen.\n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "\n",
      "        .. versionadded:: 1.2.0\n",
      "    engine_kwargs : dict, optional\n",
      "        Arbitrary keyword arguments passed to excel engine.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    ExcelWriter : Class for writing DataFrame objects into excel sheets.\n",
      "    read_excel : Read an Excel file into a pandas DataFrame.\n",
      "    read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "    io.formats.style.Styler.to_excel : Add styles to Excel sheet.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    For compatibility with :meth:`~DataFrame.to_csv`,\n",
      "    to_excel serializes lists and dicts to strings before writing.\n",
      "\n",
      "    Once a workbook has been saved it is not possible to write further\n",
      "    data without rewriting the whole workbook.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "\n",
      "    Create, write to and save a workbook:\n",
      "\n",
      "    >>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      "    ...                    index=['row 1', 'row 2'],\n",
      "    ...                    columns=['col 1', 'col 2'])\n",
      "    >>> df1.to_excel(\"output.xlsx\")  # doctest: +SKIP\n",
      "\n",
      "    To specify the sheet name:\n",
      "\n",
      "    >>> df1.to_excel(\"output.xlsx\",\n",
      "    ...              sheet_name='Sheet_name_1')  # doctest: +SKIP\n",
      "\n",
      "    If you wish to write to more than one sheet in the workbook, it is\n",
      "    necessary to specify an ExcelWriter object:\n",
      "\n",
      "    >>> df2 = df1.copy()\n",
      "    >>> with pd.ExcelWriter('output.xlsx') as writer:  # doctest: +SKIP\n",
      "    ...     df1.to_excel(writer, sheet_name='Sheet_name_1')\n",
      "    ...     df2.to_excel(writer, sheet_name='Sheet_name_2')\n",
      "\n",
      "    ExcelWriter can also be used to append to an existing Excel file:\n",
      "\n",
      "    >>> with pd.ExcelWriter('output.xlsx',\n",
      "    ...                     mode='a') as writer:  # doctest: +SKIP\n",
      "    ...     df1.to_excel(writer, sheet_name='Sheet_name_3')\n",
      "\n",
      "    To set the library that is used to write the Excel file,\n",
      "    you can pass the `engine` keyword (the default engine is\n",
      "    automatically chosen depending on the file extension):\n",
      "\n",
      "    >>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame.to_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c5f665f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function rename in module pandas.core.frame:\n",
      "\n",
      "rename(\n",
      "    self,\n",
      "    mapper: 'Renamer | None' = None,\n",
      "    *,\n",
      "    index: 'Renamer | None' = None,\n",
      "    columns: 'Renamer | None' = None,\n",
      "    axis: 'Axis | None' = None,\n",
      "    copy: 'bool | None' = None,\n",
      "    inplace: 'bool' = False,\n",
      "    level: 'Level | None' = None,\n",
      "    errors: 'IgnoreRaise' = 'ignore'\n",
      ") -> 'DataFrame | None'\n",
      "    Rename columns or index labels.\n",
      "\n",
      "    Function / dict values must be unique (1-to-1). Labels not contained in\n",
      "    a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      "    error.\n",
      "\n",
      "    See the :ref:`user guide <basics.rename>` for more.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    mapper : dict-like or function\n",
      "        Dict-like or function transformations to apply to\n",
      "        that axis' values. Use either ``mapper`` and ``axis`` to\n",
      "        specify the axis to target with ``mapper``, or ``index`` and\n",
      "        ``columns``.\n",
      "    index : dict-like or function\n",
      "        Alternative to specifying axis (``mapper, axis=0``\n",
      "        is equivalent to ``index=mapper``).\n",
      "    columns : dict-like or function\n",
      "        Alternative to specifying axis (``mapper, axis=1``\n",
      "        is equivalent to ``columns=mapper``).\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Axis to target with ``mapper``. Can be either the axis name\n",
      "        ('index', 'columns') or number (0, 1). The default is 'index'.\n",
      "    copy : bool, default True\n",
      "        Also copy underlying data.\n",
      "\n",
      "        .. note::\n",
      "            The `copy` keyword will change behavior in pandas 3.0.\n",
      "            `Copy-on-Write\n",
      "            <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      "            will be enabled by default, which means that all methods with a\n",
      "            `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      "            ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      "            future version of pandas.\n",
      "\n",
      "            You can already get the future behavior and improvements through\n",
      "            enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      "    inplace : bool, default False\n",
      "        Whether to modify the DataFrame rather than creating a new one.\n",
      "        If True then value of copy is ignored.\n",
      "    level : int or level name, default None\n",
      "        In case of a MultiIndex, only rename labels in the specified\n",
      "        level.\n",
      "    errors : {'ignore', 'raise'}, default 'ignore'\n",
      "        If 'raise', raise a `KeyError` when a dict-like `mapper`, `index`,\n",
      "        or `columns` contains labels that are not present in the Index\n",
      "        being transformed.\n",
      "        If 'ignore', existing keys will be renamed and extra keys will be\n",
      "        ignored.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or None\n",
      "        DataFrame with the renamed axis labels or None if ``inplace=True``.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    KeyError\n",
      "        If any of the labels is not found in the selected axis and\n",
      "        \"errors='raise'\".\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.rename_axis : Set the name of the axis.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    ``DataFrame.rename`` supports two calling conventions\n",
      "\n",
      "    * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      "    * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      "\n",
      "    We *highly* recommend using keyword arguments to clarify your\n",
      "    intent.\n",
      "\n",
      "    Rename columns using a mapping:\n",
      "\n",
      "    >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      "    >>> df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\n",
      "       a  c\n",
      "    0  1  4\n",
      "    1  2  5\n",
      "    2  3  6\n",
      "\n",
      "    Rename index using a mapping:\n",
      "\n",
      "    >>> df.rename(index={0: \"x\", 1: \"y\", 2: \"z\"})\n",
      "       A  B\n",
      "    x  1  4\n",
      "    y  2  5\n",
      "    z  3  6\n",
      "\n",
      "    Cast index labels to a different type:\n",
      "\n",
      "    >>> df.index\n",
      "    RangeIndex(start=0, stop=3, step=1)\n",
      "    >>> df.rename(index=str).index\n",
      "    Index(['0', '1', '2'], dtype='object')\n",
      "\n",
      "    >>> df.rename(columns={\"A\": \"a\", \"B\": \"b\", \"C\": \"c\"}, errors=\"raise\")\n",
      "    Traceback (most recent call last):\n",
      "    KeyError: ['C'] not found in axis\n",
      "\n",
      "    Using axis-style parameters:\n",
      "\n",
      "    >>> df.rename(str.lower, axis='columns')\n",
      "       a  b\n",
      "    0  1  4\n",
      "    1  2  5\n",
      "    2  3  6\n",
      "\n",
      "    >>> df.rename({1: 2, 2: 4}, axis='index')\n",
      "       A  B\n",
      "    0  1  4\n",
      "    2  2  5\n",
      "    4  3  6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame.rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "397a9b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on CallableDynamicDoc in module pandas._config.config:\n",
      "\n",
      "<pandas._config.config.CallableDynamicDoc object>\n",
      "    set_option(pat, value)\n",
      "\n",
      "    Sets the value of the specified option.\n",
      "\n",
      "    Available options:\n",
      "\n",
      "    - compute.[use_bottleneck, use_numba, use_numexpr]\n",
      "    - display.[chop_threshold, colheader_justify, date_dayfirst, date_yearfirst,\n",
      "      encoding, expand_frame_repr, float_format]\n",
      "    - display.html.[border, table_schema, use_mathjax]\n",
      "    - display.[large_repr, max_categories, max_columns, max_colwidth, max_dir_items,\n",
      "      max_info_columns, max_info_rows, max_rows, max_seq_items, memory_usage,\n",
      "      min_rows, multi_sparse, notebook_repr_html, pprint_nest_depth, precision,\n",
      "      show_dimensions]\n",
      "    - display.unicode.[ambiguous_as_wide, east_asian_width]\n",
      "    - display.[width]\n",
      "    - future.[infer_string, no_silent_downcasting]\n",
      "    - io.excel.ods.[reader, writer]\n",
      "    - io.excel.xls.[reader]\n",
      "    - io.excel.xlsb.[reader]\n",
      "    - io.excel.xlsm.[reader, writer]\n",
      "    - io.excel.xlsx.[reader, writer]\n",
      "    - io.hdf.[default_format, dropna_table]\n",
      "    - io.parquet.[engine]\n",
      "    - io.sql.[engine]\n",
      "    - mode.[chained_assignment, copy_on_write, data_manager, sim_interactive,\n",
      "      string_storage, use_inf_as_na]\n",
      "    - plotting.[backend]\n",
      "    - plotting.matplotlib.[register_converters]\n",
      "    - styler.format.[decimal, escape, formatter, na_rep, precision, thousands]\n",
      "    - styler.html.[mathjax]\n",
      "    - styler.latex.[environment, hrules, multicol_align, multirow_align]\n",
      "    - styler.render.[encoding, max_columns, max_elements, max_rows, repr]\n",
      "    - styler.sparse.[columns, index]\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    pat : str\n",
      "        Regexp which should match a single option.\n",
      "        Note: partial matches are supported for convenience, but unless you use the\n",
      "        full option name (e.g. x.y.z.option_name), your code may break in future\n",
      "        versions if new options with similar names are introduced.\n",
      "    value : object\n",
      "        New value of option.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    None\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    OptionError if no such option exists\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Please reference the :ref:`User Guide <options>` for more information.\n",
      "\n",
      "    The available options with its descriptions:\n",
      "\n",
      "    compute.use_bottleneck : bool\n",
      "        Use the bottleneck library to accelerate if it is installed,\n",
      "        the default is True\n",
      "        Valid values: False,True\n",
      "        [default: True] [currently: True]\n",
      "    compute.use_numba : bool\n",
      "        Use the numba engine option for select operations if it is installed,\n",
      "        the default is False\n",
      "        Valid values: False,True\n",
      "        [default: False] [currently: False]\n",
      "    compute.use_numexpr : bool\n",
      "        Use the numexpr library to accelerate computation if it is installed,\n",
      "        the default is True\n",
      "        Valid values: False,True\n",
      "        [default: True] [currently: True]\n",
      "    display.chop_threshold : float or None\n",
      "        if set to a float value, all float values smaller than the given threshold\n",
      "        will be displayed as exactly 0 by repr and friends.\n",
      "        [default: None] [currently: None]\n",
      "    display.colheader_justify : 'left'/'right'\n",
      "        Controls the justification of column headers. used by DataFrameFormatter.\n",
      "        [default: right] [currently: right]\n",
      "    display.date_dayfirst : boolean\n",
      "        When True, prints and parses dates with the day first, eg 20/01/2005\n",
      "        [default: False] [currently: False]\n",
      "    display.date_yearfirst : boolean\n",
      "        When True, prints and parses dates with the year first, eg 2005/01/20\n",
      "        [default: False] [currently: False]\n",
      "    display.encoding : str/unicode\n",
      "        Defaults to the detected encoding of the console.\n",
      "        Specifies the encoding to be used for strings returned by to_string,\n",
      "        these are generally strings meant to be displayed on the console.\n",
      "        [default: UTF-8] [currently: UTF-8]\n",
      "    display.expand_frame_repr : boolean\n",
      "        Whether to print out the full DataFrame repr for wide DataFrames across\n",
      "        multiple lines, `max_columns` is still respected, but the output will\n",
      "        wrap-around across multiple \"pages\" if its width exceeds `display.width`.\n",
      "        [default: True] [currently: True]\n",
      "    display.float_format : callable\n",
      "        The callable should accept a floating point number and return\n",
      "        a string with the desired format of the number. This is used\n",
      "        in some places like SeriesFormatter.\n",
      "        See formats.format.EngFormatter for an example.\n",
      "        [default: None] [currently: None]\n",
      "    display.html.border : int\n",
      "        A ``border=value`` attribute is inserted in the ``<table>`` tag\n",
      "        for the DataFrame HTML repr.\n",
      "        [default: 1] [currently: 1]\n",
      "    display.html.table_schema : boolean\n",
      "        Whether to publish a Table Schema representation for frontends\n",
      "        that support it.\n",
      "        (default: False)\n",
      "        [default: False] [currently: False]\n",
      "    display.html.use_mathjax : boolean\n",
      "        When True, Jupyter notebook will process table contents using MathJax,\n",
      "        rendering mathematical expressions enclosed by the dollar symbol.\n",
      "        (default: True)\n",
      "        [default: True] [currently: True]\n",
      "    display.large_repr : 'truncate'/'info'\n",
      "        For DataFrames exceeding max_rows/max_cols, the repr (and HTML repr) can\n",
      "        show a truncated table, or switch to the view from\n",
      "        df.info() (the behaviour in earlier versions of pandas).\n",
      "        [default: truncate] [currently: truncate]\n",
      "    display.max_categories : int\n",
      "        This sets the maximum number of categories pandas should output when\n",
      "        printing out a `Categorical` or a Series of dtype \"category\".\n",
      "        [default: 8] [currently: 8]\n",
      "    display.max_columns : int\n",
      "        If max_cols is exceeded, switch to truncate view. Depending on\n",
      "        `large_repr`, objects are either centrally truncated or printed as\n",
      "        a summary view. 'None' value means unlimited.\n",
      "\n",
      "        In case python/IPython is running in a terminal and `large_repr`\n",
      "        equals 'truncate' this can be set to 0 or None and pandas will auto-detect\n",
      "        the width of the terminal and print a truncated object which fits\n",
      "        the screen width. The IPython notebook, IPython qtconsole, or IDLE\n",
      "        do not run in a terminal and hence it is not possible to do\n",
      "        correct auto-detection and defaults to 20.\n",
      "        [default: 20] [currently: 20]\n",
      "    display.max_colwidth : int or None\n",
      "        The maximum width in characters of a column in the repr of\n",
      "        a pandas data structure. When the column overflows, a \"...\"\n",
      "        placeholder is embedded in the output. A 'None' value means unlimited.\n",
      "        [default: 50] [currently: 50]\n",
      "    display.max_dir_items : int\n",
      "        The number of items that will be added to `dir(...)`. 'None' value means\n",
      "        unlimited. Because dir is cached, changing this option will not immediately\n",
      "        affect already existing dataframes until a column is deleted or added.\n",
      "\n",
      "        This is for instance used to suggest columns from a dataframe to tab\n",
      "        completion.\n",
      "        [default: 100] [currently: 100]\n",
      "    display.max_info_columns : int\n",
      "        max_info_columns is used in DataFrame.info method to decide if\n",
      "        per column information will be printed.\n",
      "        [default: 100] [currently: 100]\n",
      "    display.max_info_rows : int\n",
      "        df.info() will usually show null-counts for each column.\n",
      "        For large frames this can be quite slow. max_info_rows and max_info_cols\n",
      "        limit this null check only to frames with smaller dimensions than\n",
      "        specified.\n",
      "        [default: 1690785] [currently: 1690785]\n",
      "    display.max_rows : int\n",
      "        If max_rows is exceeded, switch to truncate view. Depending on\n",
      "        `large_repr`, objects are either centrally truncated or printed as\n",
      "        a summary view. 'None' value means unlimited.\n",
      "\n",
      "        In case python/IPython is running in a terminal and `large_repr`\n",
      "        equals 'truncate' this can be set to 0 and pandas will auto-detect\n",
      "        the height of the terminal and print a truncated object which fits\n",
      "        the screen height. The IPython notebook, IPython qtconsole, or\n",
      "        IDLE do not run in a terminal and hence it is not possible to do\n",
      "        correct auto-detection.\n",
      "        [default: 60] [currently: 60]\n",
      "    display.max_seq_items : int or None\n",
      "        When pretty-printing a long sequence, no more then `max_seq_items`\n",
      "        will be printed. If items are omitted, they will be denoted by the\n",
      "        addition of \"...\" to the resulting string.\n",
      "\n",
      "        If set to None, the number of items to be printed is unlimited.\n",
      "        [default: 100] [currently: 100]\n",
      "    display.memory_usage : bool, string or None\n",
      "        This specifies if the memory usage of a DataFrame should be displayed when\n",
      "        df.info() is called. Valid values True,False,'deep'\n",
      "        [default: True] [currently: True]\n",
      "    display.min_rows : int\n",
      "        The numbers of rows to show in a truncated view (when `max_rows` is\n",
      "        exceeded). Ignored when `max_rows` is set to None or 0. When set to\n",
      "        None, follows the value of `max_rows`.\n",
      "        [default: 10] [currently: 10]\n",
      "    display.multi_sparse : boolean\n",
      "        \"sparsify\" MultiIndex display (don't display repeated\n",
      "        elements in outer levels within groups)\n",
      "        [default: True] [currently: True]\n",
      "    display.notebook_repr_html : boolean\n",
      "        When True, IPython notebook will use html representation for\n",
      "        pandas objects (if it is available).\n",
      "        [default: True] [currently: True]\n",
      "    display.pprint_nest_depth : int\n",
      "        Controls the number of nested levels to process when pretty-printing\n",
      "        [default: 3] [currently: 3]\n",
      "    display.precision : int\n",
      "        Floating point output precision in terms of number of places after the\n",
      "        decimal, for regular formatting as well as scientific notation. Similar\n",
      "        to ``precision`` in :meth:`numpy.set_printoptions`.\n",
      "        [default: 6] [currently: 6]\n",
      "    display.show_dimensions : boolean or 'truncate'\n",
      "        Whether to print out dimensions at the end of DataFrame repr.\n",
      "        If 'truncate' is specified, only print out the dimensions if the\n",
      "        frame is truncated (e.g. not display all rows and/or columns)\n",
      "        [default: truncate] [currently: truncate]\n",
      "    display.unicode.ambiguous_as_wide : boolean\n",
      "        Whether to use the Unicode East Asian Width to calculate the display text\n",
      "        width.\n",
      "        Enabling this may affect to the performance (default: False)\n",
      "        [default: False] [currently: False]\n",
      "    display.unicode.east_asian_width : boolean\n",
      "        Whether to use the Unicode East Asian Width to calculate the display text\n",
      "        width.\n",
      "        Enabling this may affect to the performance (default: False)\n",
      "        [default: False] [currently: False]\n",
      "    display.width : int\n",
      "        Width of the display in characters. In case python/IPython is running in\n",
      "        a terminal this can be set to None and pandas will correctly auto-detect\n",
      "        the width.\n",
      "        Note that the IPython notebook, IPython qtconsole, or IDLE do not run in a\n",
      "        terminal and hence it is not possible to correctly detect the width.\n",
      "        [default: 80] [currently: 80]\n",
      "    future.infer_string Whether to infer sequence of str objects as pyarrow string dtype, which will be the default in pandas 3.0 (at which point this option will be deprecated).\n",
      "        [default: False] [currently: False]\n",
      "    future.no_silent_downcasting Whether to opt-in to the future behavior which will *not* silently downcast results from Series and DataFrame `where`, `mask`, and `clip` methods. Silent downcasting will be removed in pandas 3.0 (at which point this option will be deprecated).\n",
      "        [default: False] [currently: False]\n",
      "    io.excel.ods.reader : string\n",
      "        The default Excel reader engine for 'ods' files. Available options:\n",
      "        auto, odf, calamine.\n",
      "        [default: auto] [currently: auto]\n",
      "    io.excel.ods.writer : string\n",
      "        The default Excel writer engine for 'ods' files. Available options:\n",
      "        auto, odf.\n",
      "        [default: auto] [currently: auto]\n",
      "    io.excel.xls.reader : string\n",
      "        The default Excel reader engine for 'xls' files. Available options:\n",
      "        auto, xlrd, calamine.\n",
      "        [default: auto] [currently: auto]\n",
      "    io.excel.xlsb.reader : string\n",
      "        The default Excel reader engine for 'xlsb' files. Available options:\n",
      "        auto, pyxlsb, calamine.\n",
      "        [default: auto] [currently: auto]\n",
      "    io.excel.xlsm.reader : string\n",
      "        The default Excel reader engine for 'xlsm' files. Available options:\n",
      "        auto, xlrd, openpyxl, calamine.\n",
      "        [default: auto] [currently: auto]\n",
      "    io.excel.xlsm.writer : string\n",
      "        The default Excel writer engine for 'xlsm' files. Available options:\n",
      "        auto, openpyxl.\n",
      "        [default: auto] [currently: auto]\n",
      "    io.excel.xlsx.reader : string\n",
      "        The default Excel reader engine for 'xlsx' files. Available options:\n",
      "        auto, xlrd, openpyxl, calamine.\n",
      "        [default: auto] [currently: auto]\n",
      "    io.excel.xlsx.writer : string\n",
      "        The default Excel writer engine for 'xlsx' files. Available options:\n",
      "        auto, openpyxl, xlsxwriter.\n",
      "        [default: auto] [currently: auto]\n",
      "    io.hdf.default_format : format\n",
      "        default format writing format, if None, then\n",
      "        put will default to 'fixed' and append will default to 'table'\n",
      "        [default: None] [currently: None]\n",
      "    io.hdf.dropna_table : boolean\n",
      "        drop ALL nan rows when appending to a table\n",
      "        [default: False] [currently: False]\n",
      "    io.parquet.engine : string\n",
      "        The default parquet reader/writer engine. Available options:\n",
      "        'auto', 'pyarrow', 'fastparquet', the default is 'auto'\n",
      "        [default: auto] [currently: auto]\n",
      "    io.sql.engine : string\n",
      "        The default sql reader/writer engine. Available options:\n",
      "        'auto', 'sqlalchemy', the default is 'auto'\n",
      "        [default: auto] [currently: auto]\n",
      "    mode.chained_assignment : string\n",
      "        Raise an exception, warn, or no action if trying to use chained assignment,\n",
      "        The default is warn\n",
      "        [default: warn] [currently: warn]\n",
      "    mode.copy_on_write : bool\n",
      "        Use new copy-view behaviour using Copy-on-Write. Defaults to False,\n",
      "        unless overridden by the 'PANDAS_COPY_ON_WRITE' environment variable\n",
      "        (if set to \"1\" for True, needs to be set before pandas is imported).\n",
      "        [default: False] [currently: False]\n",
      "    mode.data_manager : string\n",
      "        Internal data manager type; can be \"block\" or \"array\". Defaults to \"block\",\n",
      "        unless overridden by the 'PANDAS_DATA_MANAGER' environment variable (needs\n",
      "        to be set before pandas is imported).\n",
      "        [default: block] [currently: block]\n",
      "        (Deprecated, use `` instead.)\n",
      "    mode.sim_interactive : boolean\n",
      "        Whether to simulate interactive mode for purposes of testing\n",
      "        [default: False] [currently: False]\n",
      "    mode.string_storage : string\n",
      "        The default storage for StringDtype.\n",
      "        [default: auto] [currently: auto]\n",
      "    mode.use_inf_as_na : boolean\n",
      "        True means treat None, NaN, INF, -INF as NA (old way),\n",
      "        False means None and NaN are null, but INF, -INF are not NA\n",
      "        (new way).\n",
      "\n",
      "        This option is deprecated in pandas 2.1.0 and will be removed in 3.0.\n",
      "        [default: False] [currently: False]\n",
      "        (Deprecated, use `` instead.)\n",
      "    plotting.backend : str\n",
      "        The plotting backend to use. The default value is \"matplotlib\", the\n",
      "        backend provided with pandas. Other backends can be specified by\n",
      "        providing the name of the module that implements the backend.\n",
      "        [default: matplotlib] [currently: matplotlib]\n",
      "    plotting.matplotlib.register_converters : bool or 'auto'.\n",
      "        Whether to register converters with matplotlib's units registry for\n",
      "        dates, times, datetimes, and Periods. Toggling to False will remove\n",
      "        the converters, restoring any converters that pandas overwrote.\n",
      "        [default: auto] [currently: auto]\n",
      "    styler.format.decimal : str\n",
      "        The character representation for the decimal separator for floats and complex.\n",
      "        [default: .] [currently: .]\n",
      "    styler.format.escape : str, optional\n",
      "        Whether to escape certain characters according to the given context; html or latex.\n",
      "        [default: None] [currently: None]\n",
      "    styler.format.formatter : str, callable, dict, optional\n",
      "        A formatter object to be used as default within ``Styler.format``.\n",
      "        [default: None] [currently: None]\n",
      "    styler.format.na_rep : str, optional\n",
      "        The string representation for values identified as missing.\n",
      "        [default: None] [currently: None]\n",
      "    styler.format.precision : int\n",
      "        The precision for floats and complex numbers.\n",
      "        [default: 6] [currently: 6]\n",
      "    styler.format.thousands : str, optional\n",
      "        The character representation for thousands separator for floats, int and complex.\n",
      "        [default: None] [currently: None]\n",
      "    styler.html.mathjax : bool\n",
      "        If False will render special CSS classes to table attributes that indicate Mathjax\n",
      "        will not be used in Jupyter Notebook.\n",
      "        [default: True] [currently: True]\n",
      "    styler.latex.environment : str\n",
      "        The environment to replace ``\\begin{table}``. If \"longtable\" is used results\n",
      "        in a specific longtable environment format.\n",
      "        [default: None] [currently: None]\n",
      "    styler.latex.hrules : bool\n",
      "        Whether to add horizontal rules on top and bottom and below the headers.\n",
      "        [default: False] [currently: False]\n",
      "    styler.latex.multicol_align : {\"r\", \"c\", \"l\", \"naive-l\", \"naive-r\"}\n",
      "        The specifier for horizontal alignment of sparsified LaTeX multicolumns. Pipe\n",
      "        decorators can also be added to non-naive values to draw vertical\n",
      "        rules, e.g. \"\\|r\" will draw a rule on the left side of right aligned merged cells.\n",
      "        [default: r] [currently: r]\n",
      "    styler.latex.multirow_align : {\"c\", \"t\", \"b\"}\n",
      "        The specifier for vertical alignment of sparsified LaTeX multirows.\n",
      "        [default: c] [currently: c]\n",
      "    styler.render.encoding : str\n",
      "        The encoding used for output HTML and LaTeX files.\n",
      "        [default: utf-8] [currently: utf-8]\n",
      "    styler.render.max_columns : int, optional\n",
      "        The maximum number of columns that will be rendered. May still be reduced to\n",
      "        satisfy ``max_elements``, which takes precedence.\n",
      "        [default: None] [currently: None]\n",
      "    styler.render.max_elements : int\n",
      "        The maximum number of data-cell (<td>) elements that will be rendered before\n",
      "        trimming will occur over columns, rows or both if needed.\n",
      "        [default: 262144] [currently: 262144]\n",
      "    styler.render.max_rows : int, optional\n",
      "        The maximum number of rows that will be rendered. May still be reduced to\n",
      "        satisfy ``max_elements``, which takes precedence.\n",
      "        [default: None] [currently: None]\n",
      "    styler.render.repr : str\n",
      "        Determine which output to use in Jupyter Notebook in {\"html\", \"latex\"}.\n",
      "        [default: html] [currently: html]\n",
      "    styler.sparse.columns : bool\n",
      "        Whether to sparsify the display of hierarchical columns. Setting to False will\n",
      "        display each explicit level element in a hierarchical key for each column.\n",
      "        [default: True] [currently: True]\n",
      "    styler.sparse.index : bool\n",
      "        Whether to sparsify the display of a hierarchical index. Setting to False will\n",
      "        display each explicit level element in a hierarchical key for each row.\n",
      "        [default: True] [currently: True]\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> pd.set_option('display.max_columns', 4)\n",
      "    >>> df = pd.DataFrame([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "    >>> df\n",
      "       0  1  ...  3   4\n",
      "    0  1  2  ...  4   5\n",
      "    1  6  7  ...  9  10\n",
      "    [2 rows x 5 columns]\n",
      "    >>> pd.reset_option('display.max_columns')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.set_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8617f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression is ?\n",
    "\n",
    "text = '''\n",
    "Zindagi, tu aana, ek shaam milenge\n",
    "Tujhse hi teri shikayat karenge\n",
    "Zindagi, tu aana, ek shaam milenge\n",
    "Tujhse hi teri shikayat karenge\n",
    "'''\n",
    "\n",
    "\n",
    "s = text.split()\n",
    "s = pd.Series(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01dac244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Zindagi,\n",
      "1           tu\n",
      "2        aana,\n",
      "3           ek\n",
      "4        shaam\n",
      "5      milenge\n",
      "6       Tujhse\n",
      "7           hi\n",
      "8         teri\n",
      "9     shikayat\n",
      "10     karenge\n",
      "11    Zindagi,\n",
      "12          tu\n",
      "13       aana,\n",
      "14          ek\n",
      "15       shaam\n",
      "16     milenge\n",
      "17      Tujhse\n",
      "18          hi\n",
      "19        teri\n",
      "20    shikayat\n",
      "21     karenge\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e45bc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "9c2f5a0f-bbde-47c7-a9b8-c1d75f9421f6",
       "rows": [
        [
         "0",
         "Zindagi,"
        ],
        [
         "1",
         "tu"
        ],
        [
         "5",
         "milenge"
        ],
        [
         "7",
         "hi"
        ],
        [
         "8",
         "teri"
        ],
        [
         "9",
         "shikayat"
        ],
        [
         "11",
         "Zindagi,"
        ],
        [
         "12",
         "tu"
        ],
        [
         "16",
         "milenge"
        ],
        [
         "18",
         "hi"
        ],
        [
         "19",
         "teri"
        ],
        [
         "20",
         "shikayat"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 12
       }
      },
      "text/plain": [
       "0     Zindagi,\n",
       "1           tu\n",
       "5      milenge\n",
       "7           hi\n",
       "8         teri\n",
       "9     shikayat\n",
       "11    Zindagi,\n",
       "12          tu\n",
       "16     milenge\n",
       "18          hi\n",
       "19        teri\n",
       "20    shikayat\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.loc[s.str.contains('i') | s.str.contains('t')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ce61f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "71717fcc-f35c-4449-aabd-d4429e4ef44e",
       "rows": [
        [
         "0",
         "Zindagi,"
        ],
        [
         "5",
         "milenge"
        ],
        [
         "7",
         "hi"
        ],
        [
         "11",
         "Zindagi,"
        ],
        [
         "16",
         "milenge"
        ],
        [
         "18",
         "hi"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 6
       }
      },
      "text/plain": [
       "0     Zindagi,\n",
       "5      milenge\n",
       "7           hi\n",
       "11    Zindagi,\n",
       "16     milenge\n",
       "18          hi\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.loc[s.str.contains(r'^.{1}[it]', regex=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5f603",
   "metadata": {},
   "source": [
    "1+1!=2\n",
    "1+1 = 11 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
